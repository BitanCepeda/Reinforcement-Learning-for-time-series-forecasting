{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":58201,"status":"ok","timestamp":1628024269240,"user":{"displayName":"Brayan Cepeda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6_Hy7l3RbgoTiop9tm0CAFs5zeQ34jGAZ1rW4bw=s64","userId":"13104226550012534090"},"user_tz":300},"id":"j7eCj-H5a3Dx","outputId":"44168503-ad91-4bbc-c55d-5327ea5e0f65"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow==1.15.2\n","  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n","\u001b[K     |████████████████████████████████| 110.5 MB 33 kB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing\u003e=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n","Requirement already satisfied: absl-py\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.12.0)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Collecting keras-applications\u003e=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.6 MB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.15.1\n","  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","\u001b[K     |████████████████████████████████| 503 kB 41.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003c2.0,\u003e=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.19.5)\n","Requirement already satisfied: grpcio\u003e=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.34.1)\n","Requirement already satisfied: six\u003e=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.36.2)\n","Requirement already satisfied: wrapt\u003e=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.12.1)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n","Collecting tensorboard\u003c1.16.0,\u003e=1.15.0\n","  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 39.7 MB/s \n","\u001b[?25hRequirement already satisfied: astor\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n","Requirement already satisfied: protobuf\u003e=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.17.3)\n","Requirement already satisfied: google-pasta\u003e=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications\u003e=1.0.8-\u003etensorflow==1.15.2) (3.1.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (3.3.4)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (1.0.1)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (57.2.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (4.6.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py-\u003ekeras-applications\u003e=1.0.8-\u003etensorflow==1.15.2) (1.5.2)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (3.5.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (3.7.4.3)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7553 sha256=7b5ec096ba45c864445547fbe73577aa116f95dd92e70aecbf5ba4b2ec950a98\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","Successfully built gast\n","Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.5.0\n","    Uninstalling tensorflow-estimator-2.5.0:\n","      Successfully uninstalled tensorflow-estimator-2.5.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.5.0\n","    Uninstalling tensorflow-2.5.0:\n","      Successfully uninstalled tensorflow-2.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.13.0 requires gast\u003e=0.3.2, but you have gast 0.2.2 which is incompatible.\n","kapre 0.3.5 requires tensorflow\u003e=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gast","tensorboard","tensorflow"]}}},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["#SEGUNDA PARTE DE RDPG WFV\n","#RDPG AGENT \n","#!pip install tensorflow==1.15.2 "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5611,"status":"ok","timestamp":1628024354512,"user":{"displayName":"Brayan Cepeda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6_Hy7l3RbgoTiop9tm0CAFs5zeQ34jGAZ1rW4bw=s64","userId":"13104226550012534090"},"user_tz":300},"id":"xmCVwIujckbL","outputId":"bbeb2dc7-311c-466c-88e5-927b6211fdda"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From \u003cipython-input-1-4a865b56771f\u003e:149: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From \u003cipython-input-1-4a865b56771f\u003e:155: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From \u003cipython-input-1-4a865b56771f\u003e:158: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n"]}],"source":["#RDPG AGENT\n","# -*- coding: utf-8 -*-\n","\n","\n","\n","\"\"\"\n","Created on Sat May 30 20:52:21 2020\n","@author: ChefLiutao\n","The agent of RL algorithm Recurrent Detrministic Policy Gradient.\n","The Actor NNs are deployed as three-layer Fully-Connected NN.\n","The Critic NNs are deployed as RNN.\n","\"\"\"\n","\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior() \n","tf.reset_default_graph()\n","import tensorflow as tf2 #Tensorflow 1.15.2\n","from tensorflow.contrib.rnn import LSTMCell\n","  \n","\n","\n","\n","import numpy as np\n","from collections import deque\n","import random\n","\n","class RDPG():\n","    def __init__(self,\n","                 n_features,\n","#                 n_actions,\n","                 a_low,\n","                 a_high,\n","                 learning_rate_actor,\n","                 learning_rate_critic,\n","                 n_actor_hidden,\n","                 n_critic_hidden,\n","                 gamma = 0.9,\n","                 noise_varience = 3,\n","                 soft_replace = 0.1,\n","                 memory_size = 1000,\n","                 batch_size = 128):\n","        self.n_features = n_features             #dimension of states\n","#        self.n_actions = n_actions        \n","        self.a_low = a_low                       #The low bound of action sapce\n","        self.a_high = a_high                     #The high bound of action space\n","        self.lr_a = learning_rate_actor          #Learning rate of Actor NN\n","        self.lr_c = learning_rate_critic         #Learning rate of Critic NN\n","        self.n_actor_hidden = n_actor_hidden     #Number of hidden layer neurons in Actor\n","        self.n_critic_cells = n_critic_hidden   #Number of hidden layer neurons in Critic\n","        self.gamma = gamma                       #Reward discount rate\n","        self.noise_var = noise_varience          #Variance of output action distribution\n","        self.soft_replace = soft_replace         #Update speed of target networks\n","        self.memory_size = memory_size           #Size of experience replay buffer\n","        self.memory = deque(maxlen = self.memory_size)   #Experience replay buffer\n","        self.batch_size = batch_size                     \n","        \n","        self.s = tf.placeholder(dtype = tf.float32,shape = [None,self.n_features])\n","        self.s_ = tf.placeholder(dtype = tf.float32,shape = [None,self.n_features])\n","        self.r = tf.placeholder(dtype = tf.float32,shape = [None,])\n","        self.done = tf.placeholder(dtype = tf.float32,shape = [None,]) # 0 if s_ == terminal else 1\n","        \n","        self.a = self.build_Actor1()\n","        self.a_ = self.build_Actor2()\n","        self.q_sa = self.build_Critic1()      #shape:[None,] \n","        self.q_s_a_ = self.build_Critic2()    #shape:[None,]\n","        \n","        self.curr_a_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n","                                            scope = 'Actor/Current')\n","        self.targ_a_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n","                                            scope = 'Actor/Target')\n","        self.curr_c_params= tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n","                                            scope = 'Critic/Current')\n","        self.targ_c_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n","                                            scope = 'Critic/Target')\n","        \n","        # Soft replace of Targets NN parameters\n","        self.replace_a_params = [tf.assign(t,(1-self.soft_replace)*t + self.soft_replace*e) \\\n","                                 for (t,e) in zip(self.targ_a_params,self.curr_a_params)]\n","        self.replace_c_params = [tf.assign(t,(1-self.soft_replace)*t + self.soft_replace*e) \\\n","                                 for (t,e) in zip(self.targ_c_params,self.curr_c_params)]\n","        \n","        self.td_error = self.r + self.gamma*self.q_s_a_ - self.q_sa\n","        self.critic_loss = tf.reduce_mean(tf.square(self.td_error))\n","        self.actor_loss = -tf.reduce_mean(self.q_sa)\n","        \n","        self.actor_train_op = tf.train.AdamOptimizer(self.lr_a).minimize(self.actor_loss,\n","                                                    var_list = self.curr_a_params)\n","        self.critic_train_op = tf.train.AdamOptimizer(self.lr_c).minimize(self.critic_loss,\n","                                                     var_list = self.curr_c_params)\n","        \n","        self.learn_step_counter = 0\n","        self.sess = tf.Session()\n","        self.sess.run(tf.global_variables_initializer())\n","        \n","    \n","    def build_Actor1(self):\n","        '''\n","        Building Current Actor network.\n","        '''\n","        with tf.variable_scope('Actor/Current'):\n","            w_init = tf.random_normal_initializer(0,0.1)\n","            b_init = tf.constant_initializer(0.1)\n","            w1 = tf.get_variable(name = 'w1',shape = [self.n_features,self.n_actor_hidden],\n","                                 dtype = tf.float32,initializer = w_init,\n","                                 trainable = True)\n","            b1 = tf.get_variable('b1',shape = [self.n_actor_hidden,],\n","                                 dtype = tf.float32,initializer = b_init,\n","                                 trainable = True)\n","            w2 = tf.get_variable('w2',shape = [self.n_actor_hidden,1],\n","                                 dtype = tf.float32,initializer = w_init,\n","                                 trainable = True)\n","            b2 = tf.get_variable('b2',shape = [1,],\n","                                 dtype = tf.float32,initializer = b_init,\n","                                 trainable = True)\n","            hidden = tf.nn.relu(tf.matmul(self.s,w1) + b1)\n","            a = tf.matmul(hidden,w2) + b2\n","        return a[:,0]\n","#            return np.clip(np.random.normal(a,self.noise_var),self.a_low,self.a_high)\n","    \n","    def build_Actor2(self):\n","        '''\n","        Building Target Actor network.\n","        '''\n","        with tf.variable_scope('Actor/Target'):\n","            w_init = tf.random_normal_initializer(0,0.1)\n","            b_init = tf.constant_initializer(0.1)\n","            w1 = tf.get_variable('w1',shape = [self.n_features,self.n_actor_hidden],\n","                                 dtype = tf.float32,initializer = w_init,\n","                                 trainable = False)\n","            b1 = tf.get_variable('b1',shape = [self.n_actor_hidden,],\n","                                 dtype = tf.float32,initializer = b_init,\n","                                 trainable = False)\n","            w2 = tf.get_variable('w2',shape = [self.n_actor_hidden,1],\n","                                 dtype = tf.float32,initializer = w_init,\n","                                 trainable = False)\n","            b2 = tf.get_variable('b2',shape = [1,],\n","                                 dtype = tf.float32,initializer = b_init,\n","                                 trainable = False)\n","            hidden = tf.nn.relu(tf.matmul(self.s_,w1) + b1)\n","            a_ = tf.matmul(hidden,w2) + b2\n","        return a_[:,0]\n","    \n","    def build_Critic1(self):\n","        '''\n","        Building Current Critic network.\n","        '''\n","        with tf.variable_scope('Critic/Current'):\n","            w_init = tf.random_normal_initializer(0,0.1)\n","            b_init = tf.constant_initializer(0.1)\n","            \n","            rnn_cell = tf2.contrib.rnn.BasicRNNCell(self.n_critic_cells)\n","            self.init_state = rnn_cell.zero_state(batch_size=1, dtype=tf.float64)\n","            s = tf.cast(tf.expand_dims(self.s,axis = 1),tf.float64)\n","            \n","            outputs, self.final_state = tf.nn.dynamic_rnn(\n","                    cell = rnn_cell, inputs = s, \n","                    initial_state = self.init_state, time_major = True)\n","            cell_out = tf.cast(tf.reshape(outputs, [-1, self.n_critic_cells]),tf.float32)\n","            \n","            a_out = tf.layers.dense(self.a[:,np.newaxis],self.n_critic_cells,trainable = True)\n","            q_sa = tf.layers.dense(cell_out + a_out,1,tf.nn.relu,\n","                                   kernel_initializer = w_init,\n","                                   bias_initializer = b_init,trainable = True)\n","\n","        return q_sa[:,0]\n","            \n","    \n","    def build_Critic2(self):\n","        '''\n","        Building Target Critic network.\n","        '''\n","        with tf.variable_scope('Critic/Target'):\n","            w_init = tf.random_normal_initializer(0,0.1)\n","            b_init = tf.constant_initializer(0.1)\n","            \n","            rnn_cell = tf2.contrib.rnn.BasicRNNCell(self.n_critic_cells)\n","            self.init_state = rnn_cell.zero_state(batch_size=1, dtype=tf.float64)\n","            s_ = tf.cast(tf.expand_dims(self.s_,axis = 1),tf.float64)\n","            \n","            outputs, self.final_state = tf.nn.dynamic_rnn(\n","                    cell = rnn_cell, inputs = s_, \n","                    initial_state = self.init_state, time_major = True)\n","            cell_out = tf.cast(tf.reshape(outputs, [-1, self.n_critic_cells]),tf.float32)\n","            \n","            a_out = tf.layers.dense(self.a_[:,np.newaxis],self.n_critic_cells,trainable = False)\n","            q_s_a_ = tf.layers.dense(cell_out + a_out,1,tf.nn.relu,\n","                                   kernel_initializer = w_init,\n","                                   bias_initializer = b_init,trainable = False)\n","\n","        return q_s_a_[:,0]         \n","    \n","    def choose_action(self,state):\n","        state = np.reshape(state,[-1,self.n_features])\n","        action = self.sess.run(self.a,feed_dict = {self.s:state})\n","        return action\n","    \n","    def store_transition(self,state,action,reward,next_state):\n","        state,next_state = state[np.newaxis,:],next_state[np.newaxis,:]\n","        action,reward = np.array(action),np.array(reward)\n","        action = np.reshape(action,[1,-1])\n","        reward = np.reshape(reward,[1,-1])\n","#        is_done = np.reshape(is_done,[1,-1])\n","        \n","        transition = np.concatenate((state,action,reward,next_state),axis = 1)\n","        self.memory.append(transition[0,:])\n","    \n","    def learn(self):\n","        if len(self.memory) == self.memory_size:\n","            if self.learn_step_counter % 200 == 0:\n","                self.sess.run((self.replace_a_params,self.replace_c_params))\n","            \n","            self.noise_var *= 0.999\n","                \n","            batch = np.array(random.sample(self.memory,self.batch_size))\n","            batch_s = batch[:,:self.n_features]\n","            batch_a = batch[:,self.n_features:(self.n_features + 1)][:,0]\n","            batch_r = batch[:,(self.n_features + 1):(self.n_features + 2)][:,0]\n","            batch_s_ = batch[:,(self.n_features + 2):(self.n_features*2 + 2)]\n","            \n","            self.sess.run(self.actor_train_op,feed_dict = {self.s:batch_s})\n","            self.sess.run(self.critic_train_op,feed_dict = {self.s:batch_s,\n","                                                            self.a:batch_a,\n","                                                            self.s_:batch_s_,\n","                                                            self.r:batch_r})\n","\n","if __name__ == '__main__':\n","    rdpg = RDPG(5,0,1,0.03,0.01,30,30)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1628024354513,"user":{"displayName":"Brayan Cepeda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6_Hy7l3RbgoTiop9tm0CAFs5zeQ34jGAZ1rW4bw=s64","userId":"13104226550012534090"},"user_tz":300},"id":"pWXg-F58xw34"},"outputs":[],"source":["#data processing\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon May 25 11:00:32 2020\n","@author: ChefLiutao\n","This part of code is to load and preprocess time series data.\n","\"\"\"\n","\n","import numpy as np\n","\n","\n","def build_s_a(sequence,n,m):\n","    '''\n","    Args:\n","        sequence: Time series data\n","        n: The number of historical data denoting the current state\n","        m: The number of prediction steps in advance\n","    Return:\n","        state_mat: A matrix contains all states at each time step\n","        best_action: The optimal action based on each state\n","    '''\n","    n_rows = len(sequence)-n-m+1\n","    state_mat = np.zeros((n_rows,n))\n","    best_action = np.zeros(n_rows)\n","    for i in range(n_rows):\n","        state_mat[i] = sequence[i:(i+n)]\n","        best_action[i] = sequence[i+n+m-1]\n","    return state_mat,best_action\n","\n","\n","\n","def normalization(traindata,testdata):\n","    from sklearn.preprocessing import MinMaxScaler\n","    scaler = MinMaxScaler()\n","    scaler.fit(traindata)\n","    traindata_scaled = scaler.transform(traindata)\n","    testdata_scaled = scaler.transform(testdata)\n","    \n","    return traindata_scaled,testdata_scaled"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"xDlympDBx7BA"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode 0 : -805.31\n","Episode 1 : -622.85\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["#main\n","tf.reset_default_graph()\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri May 29 23:23:52 2020\n","@author: ChefLiutao\n","\"\"\"\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","\n","#####################  hyper parameters  ####################\n","N_FEATURES = 6\n","A_LOW = 0\n","A_HIGH = 1\n","LR_A = 0.001\n","LR_C = 0.003\n","N_ACTOR_HIDDEN = 30\n","N_CRITIC_HIDDEN = 30\n","MAX_EPISODES = 2  #100  #5 RMSE=19  #2 RMSE=28  #3 RMSE=9.6  #21 ???\n","MAX_STEPS = 1000\n","\n","GAMMA = 0.9                # 折扣因子\n","TAU = 0.1                 # 软更新因子\n","MEMORY_CAPACITY = 100000    #记忆库大小\n","BATCH_SIZE = 128            #批梯度下降的m\n","#############################################################\n","\n","#Load data \n","data = pd.read_csv('data.csv',encoding = 'gbk') #Carga de datasets *********************************************\n","cantidad=len(data)\n","data = data.iloc[:,0]  ##hasta el 65%, luego sacar 55 de training y 10 de test\n","\n","#Build state matrix and best action\n","state,action = build_s_a(data,N_FEATURES,1)  \n","\n","#Data split\n","SPLIT_RATE = 0.87   #WFV 87% PARA ENTRENAMIENTO para que sea 0-65% training y 65-75% test\n","split_index = round(len(state)*SPLIT_RATE)\n","train_s,train_a = state[:split_index],action[:split_index]\n","test_s,test_a = state[split_index:],action[split_index:]  \n","\n","\n","#Normalization\n","train_s_scaled,test_s_scaled = normalization(train_s,test_s)\n","A,B = train_a.max(),train_a.min()\n","train_a_scaled,test_a_scaled = (train_a-B)/(A-B),(test_a-B)/(A-B)\n","\n","# Training\n","rdpg = RDPG(N_FEATURES,A_LOW,A_HIGH,LR_A,LR_C,N_ACTOR_HIDDEN,N_CRITIC_HIDDEN)\n","for episode  in range(MAX_EPISODES):\n","    index = np.random.choice(range(len(train_s_scaled)))\n","    s = train_s_scaled[index]\n","    ep_reward = 0\n","    \n","    for step in range(MAX_STEPS):\n","        a = rdpg.choose_action(s)\n","        r = -abs(a-train_a_scaled[index])\n","        ep_reward += r\n","        index += 1\n","        s_ = train_s_scaled[index]\n","        \n","        rdpg.store_transition(s,a,r,s_)\n","        rdpg.learn()\n","        \n","        if (index == len(train_s_scaled)-1) or (step == MAX_STEPS-1):\n","            print('Episode %d : %.2f'%(episode,ep_reward))\n","            break\n","        \n","        s = s_\n","\n","# Testing\n","pred = []\n","for i in range(len(test_s_scaled)):\n","    state = test_s_scaled[i]\n","    action = rdpg.choose_action(state)\n","    pred.append(action)\n","\n","pred = [pred[i][0] for i in range(len(test_s_scaled))]\n","pred = pd.Series(pred)\n","pred = pred*(A-B)+B\n","actual = pd.Series(test_a)\n","\n","plt.scatter(pred,test_a,marker = '.')\n","plt.xlabel('Predicted Value')\n","plt.ylabel('Actual value')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9titHQf9Kuuw"},"outputs":[{"data":{"text/plain":["0         1\n","1       100\n","2       101\n","3       102\n","4       103\n","       ... \n","6035    106\n","6036    106\n","6037    107\n","6038    106\n","6039    106\n","Name: 101, Length: 6040, dtype: int64"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SAJujKWFKyC4"},"outputs":[{"data":{"text/plain":["784"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["len(test_a)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tfj3vEoEK1gX"},"outputs":[],"source":["#Convertir a dataframe las predicciones y el entrenamiento base\n","predictions1=pred.to_frame()\n","train_a=pd.DataFrame(train_a);"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2QrOTHjfK1l_"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e101.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e104.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e103.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e96.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e102.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e5245\u003c/th\u003e\n","      \u003ctd\u003e107.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e5246\u003c/th\u003e\n","      \u003ctd\u003e107.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e5247\u003c/th\u003e\n","      \u003ctd\u003e108.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e5248\u003c/th\u003e\n","      \u003ctd\u003e107.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e5249\u003c/th\u003e\n","      \u003ctd\u003e107.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e5250 rows × 1 columns\u003c/p\u003e\n","\u003c/div\u003e"],"text/plain":["          0\n","0     101.0\n","1     104.0\n","2     103.0\n","3      96.0\n","4     102.0\n","...     ...\n","5245  107.0\n","5246  107.0\n","5247  108.0\n","5248  107.0\n","5249  107.0\n","\n","[5250 rows x 1 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["train_a"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WSAowf4iK8mq"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e-1686.359447\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e-1686.399065\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e-1686.420323\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e-1686.428225\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e-1686.416601\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e779\u003c/th\u003e\n","      \u003ctd\u003e-1686.420323\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e780\u003c/th\u003e\n","      \u003ctd\u003e-1686.411385\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e781\u003c/th\u003e\n","      \u003ctd\u003e-1686.339514\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e782\u003c/th\u003e\n","      \u003ctd\u003e-1686.396641\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e783\u003c/th\u003e\n","      \u003ctd\u003e-1686.423769\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e784 rows × 1 columns\u003c/p\u003e\n","\u003c/div\u003e"],"text/plain":["               0\n","0   -1686.359447\n","1   -1686.399065\n","2   -1686.420323\n","3   -1686.428225\n","4   -1686.416601\n","..           ...\n","779 -1686.420323\n","780 -1686.411385\n","781 -1686.339514\n","782 -1686.396641\n","783 -1686.423769\n","\n","[784 rows x 1 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["predictions1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RBuTztueLAnq"},"outputs":[{"data":{"text/plain":["6034"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#SEGUNDO ENTRENAMIENTO\n","#SE UNEN train1 y predictions1\n","train2 = pd.concat([train_a,predictions1])\n","len(train2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"u1xROGEVLDyp"},"outputs":[],"source":["cantidad2=len(train2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HxBO8Wm7LRYi"},"outputs":[],"source":["#se une train2 con el dataset original\n","#Load data \n","data = pd.read_csv('raw_data_run1--1 - copia.csv',encoding = 'gbk') #Carga de datasets *********************************************\n","cantidad=len(data)\n","entrenamiento=int((cantidad/100)*65)\n","entrenamiento2=int((cantidad/100)*75)\n","data = data.iloc[entrenamiento2:cantidad,0]  \n","training2 = pd.concat([train2,data])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"auHPi42zLlNr"},"outputs":[{"data":{"text/plain":["8050"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["len(training2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zJk0JxeILnSQ"},"outputs":[],"source":["data=training2\n","data=data.iloc[:,0].astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Wp8IszmQLpap"},"outputs":[{"data":{"text/plain":["0       101\n","1       104\n","2       103\n","3        96\n","4       102\n","       ... \n","8058    103\n","8059    104\n","8060    101\n","8061    102\n","8062    101\n","Name: 0, Length: 8050, dtype: int64"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"C8CjqkT8LsAZ"},"outputs":[],"source":["#exportar la data de 0-100 para entrenar con 0-75 y testear 75-100 prediciendo 75-100 "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VPEK9fp8LuDh"},"outputs":[],"source":["data.to_csv('data1.csv')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMWICn+cH/Awrd7Hsq+ejmQ","collapsed_sections":[],"name":"RDPG WFV 2.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}