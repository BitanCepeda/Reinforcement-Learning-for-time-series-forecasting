{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":60144,"status":"ok","timestamp":1628024044771,"user":{"displayName":"Brayan Cepeda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6_Hy7l3RbgoTiop9tm0CAFs5zeQ34jGAZ1rW4bw=s64","userId":"13104226550012534090"},"user_tz":300},"id":"j7eCj-H5a3Dx","outputId":"95f80d6c-628b-43c7-f372-96b85da43241"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow==1.15.2\n","  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n","\u001b[K     |████████████████████████████████| 110.5 MB 30 kB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003c2.0,\u003e=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.19.5)\n","Collecting tensorboard\u003c1.16.0,\u003e=1.15.0\n","  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 42.2 MB/s \n","\u001b[?25hRequirement already satisfied: six\u003e=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n","Requirement already satisfied: grpcio\u003e=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.34.1)\n","Collecting keras-applications\u003e=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf\u003e=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.17.3)\n","Collecting tensorflow-estimator==1.15.1\n","  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","\u001b[K     |████████████████████████████████| 503 kB 44.5 MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n","Requirement already satisfied: wrapt\u003e=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.12.1)\n","Requirement already satisfied: astor\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.36.2)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n","Requirement already satisfied: absl-py\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.12.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n","Requirement already satisfied: keras-preprocessing\u003e=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications\u003e=1.0.8-\u003etensorflow==1.15.2) (3.1.0)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (57.2.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (3.3.4)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (1.0.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (4.6.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py-\u003ekeras-applications\u003e=1.0.8-\u003etensorflow==1.15.2) (1.5.2)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (3.5.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c1.16.0,\u003e=1.15.0-\u003etensorflow==1.15.2) (3.7.4.3)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7553 sha256=1ca0ebd79fd8463f8fe001e985f3bdc2118317ce5ace86af3e29e92f983db11e\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","Successfully built gast\n","Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.5.0\n","    Uninstalling tensorflow-estimator-2.5.0:\n","      Successfully uninstalled tensorflow-estimator-2.5.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.5.0\n","    Uninstalling tensorflow-2.5.0:\n","      Successfully uninstalled tensorflow-2.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.13.0 requires gast\u003e=0.3.2, but you have gast 0.2.2 which is incompatible.\n","kapre 0.3.5 requires tensorflow\u003e=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["gast","tensorboard","tensorflow"]}}},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["#RDPG AGENT \n","#!pip install tensorflow==1.15.2 "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6116,"status":"ok","timestamp":1628024077105,"user":{"displayName":"Brayan Cepeda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6_Hy7l3RbgoTiop9tm0CAFs5zeQ34jGAZ1rW4bw=s64","userId":"13104226550012534090"},"user_tz":300},"id":"xmCVwIujckbL","outputId":"f3fe4d41-f92e-4e70-a15d-4f0841f5d127"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From \u003cipython-input-1-4a865b56771f\u003e:149: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From \u003cipython-input-1-4a865b56771f\u003e:155: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From \u003cipython-input-1-4a865b56771f\u003e:158: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n"]}],"source":["#RDPG AGENT\n","# -*- coding: utf-8 -*-\n","\n","\n","\n","\"\"\"\n","Created on Sat May 30 20:52:21 2020\n","@author: ChefLiutao\n","The agent of RL algorithm Recurrent Detrministic Policy Gradient.\n","The Actor NNs are deployed as three-layer Fully-Connected NN.\n","The Critic NNs are deployed as RNN.\n","\"\"\"\n","\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior() \n","tf.reset_default_graph()\n","import tensorflow as tf2 #Tensorflow 1.15.2\n","from tensorflow.contrib.rnn import LSTMCell\n","  \n","\n","\n","\n","import numpy as np\n","from collections import deque\n","import random\n","\n","class RDPG():\n","    def __init__(self,\n","                 n_features,\n","#                 n_actions,\n","                 a_low,\n","                 a_high,\n","                 learning_rate_actor,\n","                 learning_rate_critic,\n","                 n_actor_hidden,\n","                 n_critic_hidden,\n","                 gamma = 0.9,\n","                 noise_varience = 3,\n","                 soft_replace = 0.1,\n","                 memory_size = 1000,\n","                 batch_size = 128):\n","        self.n_features = n_features             #dimension of states\n","#        self.n_actions = n_actions        \n","        self.a_low = a_low                       #The low bound of action sapce\n","        self.a_high = a_high                     #The high bound of action space\n","        self.lr_a = learning_rate_actor          #Learning rate of Actor NN\n","        self.lr_c = learning_rate_critic         #Learning rate of Critic NN\n","        self.n_actor_hidden = n_actor_hidden     #Number of hidden layer neurons in Actor\n","        self.n_critic_cells = n_critic_hidden   #Number of hidden layer neurons in Critic\n","        self.gamma = gamma                       #Reward discount rate\n","        self.noise_var = noise_varience          #Variance of output action distribution\n","        self.soft_replace = soft_replace         #Update speed of target networks\n","        self.memory_size = memory_size           #Size of experience replay buffer\n","        self.memory = deque(maxlen = self.memory_size)   #Experience replay buffer\n","        self.batch_size = batch_size                     \n","        \n","        self.s = tf.placeholder(dtype = tf.float32,shape = [None,self.n_features])\n","        self.s_ = tf.placeholder(dtype = tf.float32,shape = [None,self.n_features])\n","        self.r = tf.placeholder(dtype = tf.float32,shape = [None,])\n","        self.done = tf.placeholder(dtype = tf.float32,shape = [None,]) # 0 if s_ == terminal else 1\n","        \n","        self.a = self.build_Actor1()\n","        self.a_ = self.build_Actor2()\n","        self.q_sa = self.build_Critic1()      #shape:[None,] \n","        self.q_s_a_ = self.build_Critic2()    #shape:[None,]\n","        \n","        self.curr_a_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n","                                            scope = 'Actor/Current')\n","        self.targ_a_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n","                                            scope = 'Actor/Target')\n","        self.curr_c_params= tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n","                                            scope = 'Critic/Current')\n","        self.targ_c_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n","                                            scope = 'Critic/Target')\n","        \n","        # Soft replace of Targets NN parameters\n","        self.replace_a_params = [tf.assign(t,(1-self.soft_replace)*t + self.soft_replace*e) \\\n","                                 for (t,e) in zip(self.targ_a_params,self.curr_a_params)]\n","        self.replace_c_params = [tf.assign(t,(1-self.soft_replace)*t + self.soft_replace*e) \\\n","                                 for (t,e) in zip(self.targ_c_params,self.curr_c_params)]\n","        \n","        self.td_error = self.r + self.gamma*self.q_s_a_ - self.q_sa\n","        self.critic_loss = tf.reduce_mean(tf.square(self.td_error))\n","        self.actor_loss = -tf.reduce_mean(self.q_sa)\n","        \n","        self.actor_train_op = tf.train.AdamOptimizer(self.lr_a).minimize(self.actor_loss,\n","                                                    var_list = self.curr_a_params)\n","        self.critic_train_op = tf.train.AdamOptimizer(self.lr_c).minimize(self.critic_loss,\n","                                                     var_list = self.curr_c_params)\n","        \n","        self.learn_step_counter = 0\n","        self.sess = tf.Session()\n","        self.sess.run(tf.global_variables_initializer())\n","        \n","    \n","    def build_Actor1(self):\n","        '''\n","        Building Current Actor network.\n","        '''\n","        with tf.variable_scope('Actor/Current'):\n","            w_init = tf.random_normal_initializer(0,0.1)\n","            b_init = tf.constant_initializer(0.1)\n","            w1 = tf.get_variable(name = 'w1',shape = [self.n_features,self.n_actor_hidden],\n","                                 dtype = tf.float32,initializer = w_init,\n","                                 trainable = True)\n","            b1 = tf.get_variable('b1',shape = [self.n_actor_hidden,],\n","                                 dtype = tf.float32,initializer = b_init,\n","                                 trainable = True)\n","            w2 = tf.get_variable('w2',shape = [self.n_actor_hidden,1],\n","                                 dtype = tf.float32,initializer = w_init,\n","                                 trainable = True)\n","            b2 = tf.get_variable('b2',shape = [1,],\n","                                 dtype = tf.float32,initializer = b_init,\n","                                 trainable = True)\n","            hidden = tf.nn.relu(tf.matmul(self.s,w1) + b1)\n","            a = tf.matmul(hidden,w2) + b2\n","        return a[:,0]\n","#            return np.clip(np.random.normal(a,self.noise_var),self.a_low,self.a_high)\n","    \n","    def build_Actor2(self):\n","        '''\n","        Building Target Actor network.\n","        '''\n","        with tf.variable_scope('Actor/Target'):\n","            w_init = tf.random_normal_initializer(0,0.1)\n","            b_init = tf.constant_initializer(0.1)\n","            w1 = tf.get_variable('w1',shape = [self.n_features,self.n_actor_hidden],\n","                                 dtype = tf.float32,initializer = w_init,\n","                                 trainable = False)\n","            b1 = tf.get_variable('b1',shape = [self.n_actor_hidden,],\n","                                 dtype = tf.float32,initializer = b_init,\n","                                 trainable = False)\n","            w2 = tf.get_variable('w2',shape = [self.n_actor_hidden,1],\n","                                 dtype = tf.float32,initializer = w_init,\n","                                 trainable = False)\n","            b2 = tf.get_variable('b2',shape = [1,],\n","                                 dtype = tf.float32,initializer = b_init,\n","                                 trainable = False)\n","            hidden = tf.nn.relu(tf.matmul(self.s_,w1) + b1)\n","            a_ = tf.matmul(hidden,w2) + b2\n","        return a_[:,0]\n","    \n","    def build_Critic1(self):\n","        '''\n","        Building Current Critic network.\n","        '''\n","        with tf.variable_scope('Critic/Current'):\n","            w_init = tf.random_normal_initializer(0,0.1)\n","            b_init = tf.constant_initializer(0.1)\n","            \n","            rnn_cell = tf2.contrib.rnn.BasicRNNCell(self.n_critic_cells)\n","            self.init_state = rnn_cell.zero_state(batch_size=1, dtype=tf.float64)\n","            s = tf.cast(tf.expand_dims(self.s,axis = 1),tf.float64)\n","            \n","            outputs, self.final_state = tf.nn.dynamic_rnn(\n","                    cell = rnn_cell, inputs = s, \n","                    initial_state = self.init_state, time_major = True)\n","            cell_out = tf.cast(tf.reshape(outputs, [-1, self.n_critic_cells]),tf.float32)\n","            \n","            a_out = tf.layers.dense(self.a[:,np.newaxis],self.n_critic_cells,trainable = True)\n","            q_sa = tf.layers.dense(cell_out + a_out,1,tf.nn.relu,\n","                                   kernel_initializer = w_init,\n","                                   bias_initializer = b_init,trainable = True)\n","\n","        return q_sa[:,0]\n","            \n","    \n","    def build_Critic2(self):\n","        '''\n","        Building Target Critic network.\n","        '''\n","        with tf.variable_scope('Critic/Target'):\n","            w_init = tf.random_normal_initializer(0,0.1)\n","            b_init = tf.constant_initializer(0.1)\n","            \n","            rnn_cell = tf2.contrib.rnn.BasicRNNCell(self.n_critic_cells)\n","            self.init_state = rnn_cell.zero_state(batch_size=1, dtype=tf.float64)\n","            s_ = tf.cast(tf.expand_dims(self.s_,axis = 1),tf.float64)\n","            \n","            outputs, self.final_state = tf.nn.dynamic_rnn(\n","                    cell = rnn_cell, inputs = s_, \n","                    initial_state = self.init_state, time_major = True)\n","            cell_out = tf.cast(tf.reshape(outputs, [-1, self.n_critic_cells]),tf.float32)\n","            \n","            a_out = tf.layers.dense(self.a_[:,np.newaxis],self.n_critic_cells,trainable = False)\n","            q_s_a_ = tf.layers.dense(cell_out + a_out,1,tf.nn.relu,\n","                                   kernel_initializer = w_init,\n","                                   bias_initializer = b_init,trainable = False)\n","\n","        return q_s_a_[:,0]         \n","    \n","    def choose_action(self,state):\n","        state = np.reshape(state,[-1,self.n_features])\n","        action = self.sess.run(self.a,feed_dict = {self.s:state})\n","        return action\n","    \n","    def store_transition(self,state,action,reward,next_state):\n","        state,next_state = state[np.newaxis,:],next_state[np.newaxis,:]\n","        action,reward = np.array(action),np.array(reward)\n","        action = np.reshape(action,[1,-1])\n","        reward = np.reshape(reward,[1,-1])\n","#        is_done = np.reshape(is_done,[1,-1])\n","        \n","        transition = np.concatenate((state,action,reward,next_state),axis = 1)\n","        self.memory.append(transition[0,:])\n","    \n","    def learn(self):\n","        if len(self.memory) == self.memory_size:\n","            if self.learn_step_counter % 200 == 0:\n","                self.sess.run((self.replace_a_params,self.replace_c_params))\n","            \n","            self.noise_var *= 0.999\n","                \n","            batch = np.array(random.sample(self.memory,self.batch_size))\n","            batch_s = batch[:,:self.n_features]\n","            batch_a = batch[:,self.n_features:(self.n_features + 1)][:,0]\n","            batch_r = batch[:,(self.n_features + 1):(self.n_features + 2)][:,0]\n","            batch_s_ = batch[:,(self.n_features + 2):(self.n_features*2 + 2)]\n","            \n","            self.sess.run(self.actor_train_op,feed_dict = {self.s:batch_s})\n","            self.sess.run(self.critic_train_op,feed_dict = {self.s:batch_s,\n","                                                            self.a:batch_a,\n","                                                            self.s_:batch_s_,\n","                                                            self.r:batch_r})\n","\n","if __name__ == '__main__':\n","    rdpg = RDPG(5,0,1,0.03,0.01,30,30)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1628024077106,"user":{"displayName":"Brayan Cepeda","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj6_Hy7l3RbgoTiop9tm0CAFs5zeQ34jGAZ1rW4bw=s64","userId":"13104226550012534090"},"user_tz":300},"id":"pWXg-F58xw34"},"outputs":[],"source":["#data processing\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon May 25 11:00:32 2020\n","@author: ChefLiutao\n","This part of code is to load and preprocess time series data.\n","\"\"\"\n","\n","import numpy as np\n","\n","\n","def build_s_a(sequence,n,m):\n","    '''\n","    Args:\n","        sequence: Time series data\n","        n: The number of historical data denoting the current state\n","        m: The number of prediction steps in advance\n","    Return:\n","        state_mat: A matrix contains all states at each time step\n","        best_action: The optimal action based on each state\n","    '''\n","    n_rows = len(sequence)-n-m+1\n","    state_mat = np.zeros((n_rows,n))\n","    best_action = np.zeros(n_rows)\n","    for i in range(n_rows):\n","        state_mat[i] = sequence[i:(i+n)]\n","        best_action[i] = sequence[i+n+m-1]\n","    return state_mat,best_action\n","\n","\n","\n","def normalization(traindata,testdata):\n","    from sklearn.preprocessing import MinMaxScaler\n","    scaler = MinMaxScaler()\n","    scaler.fit(traindata)\n","    traindata_scaled = scaler.transform(traindata)\n","    testdata_scaled = scaler.transform(testdata)\n","    \n","    return traindata_scaled,testdata_scaled"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDlympDBx7BA"},"outputs":[],"source":["#main\n","tf.reset_default_graph()\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri May 29 23:23:52 2020\n","@author: ChefLiutao\n","\"\"\"\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","\n","#####################  hyper parameters  ####################\n","N_FEATURES = 6\n","A_LOW = 0\n","A_HIGH = 1\n","LR_A = 0.001\n","LR_C = 0.003\n","N_ACTOR_HIDDEN = 30\n","N_CRITIC_HIDDEN = 30\n","MAX_EPISODES = 2  #100  #5 RMSE=19  #2 RMSE=28  #3 RMSE=9.6  #21 ???\n","MAX_STEPS = 1000\n","\n","GAMMA = 0.9                # 折扣因子\n","TAU = 0.1                 # 软更新因子\n","MEMORY_CAPACITY = 100000    #记忆库大小\n","BATCH_SIZE = 128            #批梯度下降的m\n","#############################################################\n","\n","#Load data \n","data = pd.read_csv('raw_data_run1--22 - copia.csv',encoding = 'gbk') #Carga de datasets *********************************************\n","cantidad=len(data)\n","entrenamiento=int((cantidad/100)*65)\n","data = data.iloc[:entrenamiento,0]  ##hasta el 65%, luego sacar 55 de training y 10 de test\n","\n","#Build state matrix and best action\n","state,action = build_s_a(data,N_FEATURES,1)\n","\n","#Data split\n","SPLIT_RATE = 0.85   #WFV 85% PARA ENTRENAMIENTO para que sea 0-55% training y 55-65% test\n","split_index = round(len(state)*SPLIT_RATE)\n","train_s,train_a = state[:split_index],action[:split_index]\n","test_s,test_a = state[split_index:],action[split_index:]  \n","\n","\n","#Normalization\n","train_s_scaled,test_s_scaled = normalization(train_s,test_s)\n","A,B = train_a.max(),train_a.min()\n","train_a_scaled,test_a_scaled = (train_a-B)/(A-B),(test_a-B)/(A-B)\n","\n","# Training\n","rdpg = RDPG(N_FEATURES,A_LOW,A_HIGH,LR_A,LR_C,N_ACTOR_HIDDEN,N_CRITIC_HIDDEN)\n","for episode  in range(MAX_EPISODES):\n","    index = np.random.choice(range(len(train_s_scaled)))\n","    s = train_s_scaled[index]\n","    ep_reward = 0\n","    \n","    for step in range(MAX_STEPS):\n","        a = rdpg.choose_action(s)\n","        r = -abs(a-train_a_scaled[index])\n","        ep_reward += r\n","        index += 1\n","        s_ = train_s_scaled[index]\n","        \n","        rdpg.store_transition(s,a,r,s_)\n","        rdpg.learn()\n","        \n","        if (index == len(train_s_scaled)-1) or (step == MAX_STEPS-1):\n","            print('Episode %d : %.2f'%(episode,ep_reward))\n","            break\n","        \n","        s = s_\n","\n","# Testing\n","pred = []\n","for i in range(len(test_s_scaled)):\n","    state = test_s_scaled[i]\n","    action = rdpg.choose_action(state)\n","    pred.append(action)\n","\n","pred = [pred[i][0] for i in range(len(test_s_scaled))]\n","pred = pd.Series(pred)\n","pred = pred*(A-B)+B\n","actual = pd.Series(test_a)\n","\n","plt.scatter(pred,test_a,marker = '.')\n","plt.xlabel('Predicted Value')\n","plt.ylabel('Actual value')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9titHQf9Kuuw"},"outputs":[{"data":{"text/plain":["0       101\n","1       105\n","2         1\n","3        87\n","4       103\n","       ... \n","5235    106\n","5236    107\n","5237    107\n","5238    106\n","5239    107\n","Name: 1, Length: 5240, dtype: int64"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SAJujKWFKyC4"},"outputs":[{"data":{"text/plain":["785"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["len(test_a)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tfj3vEoEK1gX"},"outputs":[],"source":["#Convertir a dataframe las predicciones y el entrenamiento base\n","predictions1=pred.to_frame()\n","train_a=pd.DataFrame(train_a);"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2QrOTHjfK1l_"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e101.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e100.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e101.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e102.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4444\u003c/th\u003e\n","      \u003ctd\u003e107.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4445\u003c/th\u003e\n","      \u003ctd\u003e108.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4446\u003c/th\u003e\n","      \u003ctd\u003e107.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4447\u003c/th\u003e\n","      \u003ctd\u003e107.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4448\u003c/th\u003e\n","      \u003ctd\u003e106.0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e4449 rows × 1 columns\u003c/p\u003e\n","\u003c/div\u003e"],"text/plain":["          0\n","0     101.0\n","1       1.0\n","2     100.0\n","3     101.0\n","4     102.0\n","...     ...\n","4444  107.0\n","4445  108.0\n","4446  107.0\n","4447  107.0\n","4448  106.0\n","\n","[4449 rows x 1 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["train_a"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WSAowf4iK8mq"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e-1643.488047\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e-1642.956606\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e-1643.035587\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e-1637.483828\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e-1636.601358\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e780\u003c/th\u003e\n","      \u003ctd\u003e-1635.059384\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e781\u003c/th\u003e\n","      \u003ctd\u003e-1633.181382\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e782\u003c/th\u003e\n","      \u003ctd\u003e-1635.098569\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e783\u003c/th\u003e\n","      \u003ctd\u003e-1637.331681\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e784\u003c/th\u003e\n","      \u003ctd\u003e-1635.771135\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e785 rows × 1 columns\u003c/p\u003e\n","\u003c/div\u003e"],"text/plain":["               0\n","0   -1643.488047\n","1   -1642.956606\n","2   -1643.035587\n","3   -1637.483828\n","4   -1636.601358\n","..           ...\n","780 -1635.059384\n","781 -1633.181382\n","782 -1635.098569\n","783 -1637.331681\n","784 -1635.771135\n","\n","[785 rows x 1 columns]"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["predictions1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RBuTztueLAnq"},"outputs":[{"data":{"text/plain":["5234"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#SEGUNDO ENTRENAMIENTO\n","#SE UNEN train1 y predictions1\n","train2 = pd.concat([train_a,predictions1])\n","len(train2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"u1xROGEVLDyp"},"outputs":[],"source":["cantidad2=len(train2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HxBO8Wm7LRYi"},"outputs":[],"source":["#se une train2 con el dataset original\n","#Load data \n","data = pd.read_csv('raw_data_run1--22 - copia.csv',encoding = 'gbk') #Carga de datasets *********************************************\n","cantidad=len(data)\n","entrenamiento=int((cantidad/100)*65)\n","entrenamiento2=int((cantidad/100)*75)\n","data = data.iloc[entrenamiento:entrenamiento2,0]  ##hasta el 75%, luego sacar 65 de training y 10 de test\n","training2 = pd.concat([train2,data])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"auHPi42zLlNr"},"outputs":[{"data":{"text/plain":["6041"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["len(training2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zJk0JxeILnSQ"},"outputs":[],"source":["data=training2\n","data=data.iloc[:,0].astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Wp8IszmQLpap"},"outputs":[{"data":{"text/plain":["0       101\n","1         1\n","2       100\n","3       101\n","4       102\n","       ... \n","6042    106\n","6043    106\n","6044    107\n","6045    106\n","6046    106\n","Name: 0, Length: 6041, dtype: int64"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"C8CjqkT8LsAZ"},"outputs":[],"source":["#exportar la data de 0-65 para entrenar con 0-65 y testear 65-75 prediciendo 65-75 y concatenando\n","#para después exportar de nuevo las 0-75 para hacer la última ejecución"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VPEK9fp8LuDh"},"outputs":[],"source":["data.to_csv('data.csv')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPxysVG/+bRDIo3pJGhX1lv","collapsed_sections":[],"name":"RDPG WFV 1.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}